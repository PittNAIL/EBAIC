<!DOCTYPE html>
<html>
  <head>
    
    <title>EBAIC 2023</title>
    <meta charset="utf-8" />
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://pro.fontawesome.com/releases/v5.10.0/css/all.css" integrity="sha384-AYmEC3Yw5cVb3ZcuHtOA93w35dYTsvhLPVnYs9eStHfGJvOvKxVfELGroGkvsg+p" crossorigin="anonymous"/>
    
    <link
      rel="stylesheet"
      
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css"
      
    >
    
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>
    
    
    <script src="https://pittnail.github.io/EBAIC/js/blockquote.js"></script>
    <script src="https://pittnail.github.io/EBAIC/js/img.js"></script>
    
    
  </head>
  <body class="d-flex flex-column min-vh-100">
    
      <div class="w-100">
        <img src="https://pittnail.github.io/EBAIC/banner.png" class="w-100" />
      </div>
    
    
    
    
    <nav class="
      navbar
      navbar-expand-lg
      navbar-dark
      bg-dark
    ">
      <div class="container-fluid">
        <a class="navbar-brand"
          href="https:&#x2F;&#x2F;pittnail.github.io&#x2F;EBAIC"
          title="The First International Workshop on Ethics and Bias of Artificial Intelligence in Clinical Applications (EBAIC 2023)"
        >EBAIC 2023</a>
        <button
          class="navbar-toggler"
          type="button"
          data-bs-toggle="collapse"
          data-bs-target="#navbarColor02"
          aria-controls="navbarColor02"
          aria-expanded="false"
          aria-label="Toggle navigation"
        >
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarColor02">
          <ul class="navbar-nav me-auto">
            
            
            
          </ul>
          
        </div>
      </div>
    </nav>
    <main class="container mx-auto my-5">
      
  
  
    <h1 class="px-3">EBAIC 2023</h1>
  
  
  
    <div class="content px-3"><p>at <a href="https://ieeeichi.github.io/ICHI2023/">ICHI 2023</a><br />
June 26th, 2023, Houston, Texas<br />
<a href="ICHI_EBAIC2023_Flyer.pdf">Click here and get our flyer!</a></p>
<h3 id="agenda">Agenda</h3>
<hr />
<img alt="Agenda" src="agenda.png" width="640">
<h3 id="opening-keynote">Opening Keynote</h3>
<hr />
<img alt="Fei Wang" src="feiwang.png" width="150">
<br>
<p><strong>Fei Wang, PhD</strong><br />
Associate Professor of Health Informatics.<br />
Department of Population Health Sciences.<br />
Director. Institute of AI in Digital Health.<br />
Weill Cornell Medicine. Cornell University.</p>
<p><strong>Talk Title</strong>: Towards Building Trustworthy Machine Learning Models in Medicine: Accuracy,
Fairness, Explainability, and All That</p>
<p><strong>Abstract</strong>: Machine learning (ML) is playing a more and more important role in medicine. One of
the main reasons that ML models caught lots of attention is their superior quantitative performance.
Recent research and practice pointed out that we also need to consider other aspects, such as model
fairness and explainability. There exist tradeoffs among those different indices, so it is
challenging to achieve all of them simultaneously. In this presentation, I will discuss the
relationships among these different indices, introduce some of our work on joint optimization of
multiple of them, and talk about future directions.</p>
<p><strong>Bio</strong>: Fei Wang is an Associate Professor in Division of Health Informatics, Department of
Population Health Sciences, Weill Cornell Medicine (WCM), Cornell University. He is also the
founding director of the WCM institute of AI for Digital Health (AIDH). His major research interest
is AI and digital health. He has published more than 300 papers on the top venues of related areas
such as ICML, KDD, NIPS, CVPR, AAAI, IJCAI, Nature Medicine, JAMA Internal Medicine, Annals of
Internal Medicine, Lancet Digital Health, etc. His papers have received over 24,000 citations so far
with an H-index 76. His (or his students’) papers have won 8 best paper (or nomination) awards at
top international conferences on data mining and medical informatics. His team won the championship
of the AACC PTHrP result prediction challenge in 2022, NIPS/Kaggle Challenge on Classification of
Clinically Actionable Genetic Mutations in 2017 and Parkinson's Progression Markers' Initiative data
challenge organized by Michael J. Fox Foundation in 2016. Dr. Wang is the recipient of the NSF
CAREER Award in 2018, as well as the inaugural research leadership award in IEEE International
Conference on Health Informatics (ICHI) 2019. Dr. Wang also received prestigious industry awards
such as the Sanofi iDEA Award (2021), Google Faculty Research Award (2020) and Amazon AWS Machine
Learning for Research Award (2017, 2019 and 2022). Dr. Wang’s Research has been supported by a
diverse set of agencies including NSF, NIH, ONR, PCORI, MJFF, AHA, etc. Dr. Wang is the past chair
of the Knowledge Discovery and Data Mining working group in American Medical Informatics Association
(AMIA). Dr. Wang is a fellow of AMIA, a fellow of IAHSI, a fellow of ACMI and a distinguished
member.</p>
<h3 id="closing-keynote">Closing Keynote</h3>
<hr />
<p>Characterization of Stigmatizing Language in Medical Records</p>
<p><strong>Abstract</strong>: Widespread disparities in clinical outcomes exist between different demographic groups
in the United States. A new line of work in medical sociology has demonstrated physicians often use
stigmatizing language in electronic medical records within certain groups, such as black patients,
which may exacerbate disparities. In this study, we characterize these instances at scale using a
series of domain-informed NLP techniques. We highlight important differences between this task and
analogous bias-related tasks studied within the NLP community (e.g., classifying microaggressions).
Our study establishes a foundation for NLP researchers to contribute timely insights to a problem
domain brought to the forefront by recent legislation regarding clinical documentation transparency.
We release data, code, and models.</p>
<p><strong>Bio</strong>: Keith Harrigian is a 4th year PhD Student in Computer Science at Johns Hopkins University.
With his advisor Mark Dredze, Keith researches computational and statistical methods for modeling
natural language. He is particularly interested in developing robust and stable machine learning
models for application in the healthcare domain. Prior to joining Johns Hopkins, Keith was a Senior
Quantitative Analyst at Warner Media where he leveraged machine learning and natural language
processing to mine social media data for applications to film and television marketing. He holds a
M.S.E in Computer Science from Johns Hopkins University and a B.S. in Mathematics with minors in
Physics and Music from Northeastern University. He is currently on leave from JHU, working as a
machine learning intern at Netflix.</p>
<h3 id="call-for-papers-participation">Call for Papers / Participation</h3>
<hr />
<p>The volume of Electronic Health Record (EHR) data has grown dramatically in the past decade due to
the wide adoption of EHR systems in healthcare systems. The availability of large amounts of
multimodal clinical data has fostered the application of Artificial Intelligence (AI) in clinical
care including in clinical decision support, patient management, as well as in clinical and
translational research, such as digital phenotyping, cohort discovery, and in-silico trials. Despite
the promising potential of AI in clinical applications, its regular use comes with bias and ethical
challenges. As highlighted by recent studies, disparities in health care, although may start at the
collection of clinical data, could be amplified with the development of AI technologies.</p>
<h3 id="topics-of-interest">Topics of interest</h3>
<hr />
<p>Any original research related to ethics and bias of AI in clinical applications. The relevant AI
techniques include, but are not limited to, natural language processing, medical imaging, deep
learning, predictive modeling, human computer interface, Internet of Things, and more. Clinical
applications include, but are not limited to, clinical decision support, clinical research,
translational research, consumer applications, robotics.</p>
<p>Other relevant topics include: AI for health equity, AI for health disparity,
transparency/interpretability/explainability of AI techniques in clinical applications, data bias,
algorithmic bias, human bias of AI techniques, fairness metrics, fairness evaluation, fairness
tools, reasoning, practical and technical solutions to mitigate the bias, and more.</p>
<p>Finally, we will consider limited types of position papers on AI ethics/bias. This would include
position papers from individuals/groups that are part of a community that has historically been
adversely impacted by artificial intelligence, bias, or health disparities. We will also consider
position papers from institutions playing key roles in mitigating the impact of bias in clinical
applications.</p>
<h3 id="program-at-a-glance">Program-at-a-Glance</h3>
<hr />
<h4 id="scientific-session">Scientific Session</h4>
<ul>
<li>Keynote Talk
<ul>
<li><a href="https://wcm-wanglab.github.io/">Fei Wang</a>, PhD, FACMI, FAMIA, FIAHSI, ACM Distinguished Member.<br />
Associate Professor of Health Informatics, Weill Cornell Medicine. Founding Director. WCM
Institute of AI for Digital Health.</li>
</ul>
</li>
<li>Oral Presentations &amp; Posters
<ul>
<li>Submission Types:
<ul>
<li><strong>Regular Papers</strong>: 10 pages with up to 2 extra pages for references/appendices.
<ul>
<li>Will describe mature ideas, where a substantial amount of implementation, experimentation,
or data collection and analysis has been completed.</li>
</ul>
</li>
<li><strong>Short Papers</strong>: 6 pages with up to 1 extra page for references/appendices.
<ul>
<li>Will describe innovative ideas, where preliminary implementation and validation work have
been conducted.</li>
</ul>
</li>
<li><strong>Poster Submissions</strong>: 2 pages with up to 1 extra page for references/appendices.
<ul>
<li>Will present innovative ideas, late-breaking work, concepts, work-in-progress, early stages
of research, and preliminary results from implementation and validations to academic and
industrial audience.</li>
</ul>
</li>
<li><strong>Position Papers</strong>: 4 pages with up to 2 extra pages for references/appendices.
<ul>
<li>Will present an arguable opinion about AI ethics/bias and its impact.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="tutorial-hackathon-session">Tutorial/Hackathon Session</h4>
<p>The purpose of the tutorial/hackathon session is to raise awareness of the problem of bias in
clinical data and AI algorithms with the ultimate goal of creating innovative approaches that can
help reduce or eliminate bias in clinical data and AI. Participants may be students, researchers,
and data scientists who are interested in applying AI to clinical applications. Complete this <a href="https://forms.gle/3mtLQcKijiYi3PrW8">form</a> to register the Tutorial/Hackathon Session.</p>
<ul>
<li>Track I: Clinical Natural Language Processing
<ul>
<li>Data: de-identified clinical notes from MIMIC III</li>
<li>Algorithm: Rule-based NLP algorithm</li>
<li>Task: Understand how stigmatizing language in clinical notes varies by patients' medical
condition and race/ethnicity</li>
<li>Pre-requisite: Complete required training and sign the data use agreement for the MIMIC III data
access at <a href="https://physionet.org/content/mimiciii/1.4/">https://physionet.org/content/mimiciii/1.4/</a></li>
<li>Codebase: <a href="https://github.com/pitthexai/ICHI2023_EBAIC">https://github.com/pitthexai/ICHI2023_EBAIC</a></li>
</ul>
</li>
<li>Track II: Medical Imaging
<ul>
<li>Data: Knee X-ray images from NIH OAI publicly available dataset</li>
<li>Algorithm: Convolutional Neural Networks</li>
<li>Task: Understand how knee joint segmentation and measurement varies by different racial or
gender groups, and imbalanced training data</li>
<li>Codebase and dataset: <a href="https://github.com/pitthexai/ICHI2023_EBAIC">https://github.com/pitthexai/ICHI2023_EBAIC</a></li>
</ul>
</li>
</ul>
<h3 id="submission-and-review">Submission and Review</h3>
<hr />
<p>Anyone who is interested in ethics and bias of AI in clinical applications is invited to submit
their work to the EBAIC 2023.</p>
<p>Authors can log in at <a href="https://easychair.org/conferences/?conf=ieeeichi2023">https://easychair.org/conferences/?conf=ieeeichi2023</a> and submit
their papers under the &quot;ebaic&quot; track. All submitted papers will be peer-reviewed by domain experts.</p>
<p>Accepted papers will also be invited to publish an extended version in the <a href="https://www.springer.com/journal/41666">Journal of Healthcare Informatics Research</a> with an accelerated peer-review process and a free of charge for publication (except Open Access).</p>
<h3 id="more-information">More Information</h3>
<hr />
<p>For more information regarding paper template and review process, please visit
<a href="https://ieeeichi.github.io/ICHI2023/call_for_papers.html">https://ieeeichi.github.io/ICHI2023/call_for_papers.html</a>.</p>
<p>All submissions will be published in <a href="https://ieeexplore.ieee.org/">IEEE Xplore</a> and indexed in other Abstracting and
Indexing (A&amp;I) databases. Accepted papers have an oral presentation slot at the conference.</p>
<h3 id="organizers">Organizers</h3>
<hr />
<h4 id="co-chairs">Co-Chairs</h4>
<ul>
<li><a href="https://www.shrs.pitt.edu/people/yanshan-wang">Yanshan Wang, PhD</a>, University of Pittsburgh, Pittsburgh, PA, USA</li>
<li><a href="https://www.mayo.edu/research/faculty/liu-hongfang-ph-d/bio-00055092">Hongfang Liu, PhD</a>, Mayo Clinic, Rochester, MN, USA</li>
<li><a href="https://aptafti.github.io/">Ahmad P. Tafti, PhD</a>, University of Pittsburgh, Pittsburgh, PA, USA</li>
<li><a href="https://sbmi.uth.edu/faculty-and-staff/kirk-roberts.htm">Kirk Roberts, PhD</a>, The University of Texas Health Science Center at Houston, USA</li>
</ul>
<h4 id="technology-chair">Technology Chair</h4>
<ul>
<li><a href="https://oniani.ai/">David Oniani</a>, University of Pittsburgh, Pittsburgh, PA, USA</li>
</ul>
<h4 id="publication-chair">Publication Chair</h4>
<ul>
<li><a href="https://www.isp.pitt.edu/people/sonish-sivarajkumar">Sonish Sivarajkumar</a>, University of Pittsburgh, Pittsburgh, PA, USA</li>
</ul>
<h4 id="steering-committee">Steering Committee</h4>
<ul>
<li><a href="https://www.heinz.cmu.edu/faculty-research/profiles/padman-rema/">Rema Padman, PhD</a>, Carnegie Mellon University, USA</li>
<li><a href="https://wcm-wanglab.github.io/">Fei Wang, PhD</a>, Weill Cornell Medicine, USA</li>
<li><a href="https://www.biostat.wisc.edu/~vsingh/">Vikas Singh, PhD</a>, University of Wisconsin-Madison, USA</li>
<li><a href="https://www.hsph.harvard.edu/population-development/people/hossein-estiri-phd/">Hossein Estiri, PhD</a>, Harvard Medical School, USA</li>
</ul>
<h3 id="important-dates">Important Dates</h3>
<hr />
<ul>
<li>Deadline for all submissions: March 31st, 2023</li>
<li>Notification of decisions: April 11th, 2023</li>
<li>Camera-ready due: April 21st, 2023</li>
<li>Workshop date: June 26th, 2023</li>
</ul>
<h3 id="sponsorship">Sponsorship</h3>
<hr />
<ul>
<li><a href="https://bioethics.pitt.edu/">University of Pittsburgh Center for Bioethics and Health Law</a></li>
<li><a href="https://commonfund.nih.gov/bridge2ai">NIH Bridge to Artificial Intelligence (Bridge2AI)</a></li>
</ul>
</div>
  
	
  
  

  

    </main>
    
    
    
  </body>
</html>
